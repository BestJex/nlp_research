path_root: "data/match/"
ori_path: "intent.csv"
no_train_path: "no_train.csv"
index_path: "index.csv"
relation_path: "relation.csv"
test_path: "test.csv"
classes_path: "{encoder_type}classes"
dict_path: "{encoder_type}/dict.pkl"
checkpoint_path: "{encoder_type}/checkpoint"
model_path: "{encoder_type}/model.pb"
label_path: "{encoder_type}/label"
cache_vec_path: "{encoder_type}/cache.vec.pkl"
tfrecords_path: "tfrecords"
export_dir_path: "{encoder_type}/model"




num_epochs: 15000

maxlen: 20

learning_rate: 0.0001

valid_step: 1000 #valid one time every valid_step 
early_stop: True
#embedding_type: "word_embedding"
#embedding_size: 128
embedding_type: "char_embedding"
embedding_size: 300
rand_embedding: False

use_language_model: False

# rand_embedding: False
# sim_mode=cross: 对于交互的匹配方法
# sim_mode=represent: 基于表示的匹配方法

optimizer_type: "Adam"
use_clr: False
clr_mode: 'triangular'

#class/89   pair/2
tfrecords_mode: "class"
loss_type: "hinge_loss"
loss_type: "am_softmax_loss"
sub_loss_type: "hard"
max_steps: 3000
num_class: 91
batch_size: 64

test_size: 1
batch_mode: "random"  #(random/supervised)
# batch_mode: "supervised"
margin: 0.5
semi_hard: True
score_thre: 0.8
config_type: 10
config: 
  0: {encoder_type: "match_pyramid", sim_mode: "cross", num_output: 1, 
    tfrecords_mode: "pair", num_pair: 2, loss_type: "sigmoid_loss"}
  1: {encoder_type: "abcnn", sim_mode: "cross", num_output: 1, learning_rate: 0.0005, 
    tfrecords_mode: "pair", num_pair: 2, loss_type: "sigmoid_loss"}
  2: {encoder_type: "esim", sim_mode: "cross", loss_type: 'l2_loss', num_output: 1, learning_rate: 0.001, 
    tfrecords_mode: "pair", num_pair: 2, loss_type: "sigmoid_loss"}

  10: {encoder_type: "fasttext", sim_mode: "represent", num_output: 256, learning_rate: 0.00001}
  11: {encoder_type: "rnn", rnn_type: "gru", sim_mode: "represent", num_output: 256, learning_rate: 0.001}
  12: {encoder_type: "rnn", rnn_type: "lstm", sim_mode: "represent", num_output: 128, learning_rate: 0.001}
  13: {encoder_type: "rcnn", rnn_type: "lstm", sim_mode: "represent", num_output: 128, learning_rate: 0.001}
  14: {encoder_type: "attention_rnn", rnn_type: "gru", sim_mode: "represent", num_output: 128, learning_rate: 0.001}
  15: {encoder_type: "attention_rnn", rnn_type: "lstm", sim_mode: "represent", num_output: 128, learning_rate: 0.001}
  21: {encoder_type: "text_cnn", sim_mode: "represent", num_output: 256, learning_rate: 0.0001}
  22: {encoder_type: "transformer", sim_mode: "represent", num_output: 256, 
    learning_rate: 0.00001, embedding_size: 128, rand_embedding: True}
  23: {encoder_type: "bert", sim_mode: "represent", learning_rate: 0.00002, use_language_model: True, valid_step: 20000, num_output: 1}

mode: "train"  #train\test\test_one
#mode: "test"  #train\test\test_one
#mode: "test_one"  #train\test\test_one
