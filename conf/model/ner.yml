########## path ##########################
path_root: "data/ner/"
ori_path: "train_data"
# ori_path: "intent_ner.csv"


classes_path: "{encoder_type}/classes"
dict_path: "{encoder_type}/dict.pkl"
checkpoint_path: "{encoder_type}/checkpoint"
model_path: "{encoder_type}/model.pb"
label_path: "{encoder_type}/label"
tfrecords_path: "{encoder_type}/tfrecords"
export_dir_path: "{encoder_type}/model"
########### embedding ###########
embedding_size: 128
embedding_type: 'char_embedding'
rand_embedding: True
use_language_model: False

############# optim #############
base_learning_rate: 0.00001
learning_rate: 0.001
optimizer_type: "Nadam"
#keep_prob: 0.5
clip_grad: 5
use_crf: True

############# clr #####################
use_clr: True
clr_mode: 'triangular'
max_learning_rate: 0.1
step_size: 100

############ data ###############
# maxlen: 128
maxlen: 128
batch_size: 64
dev_size: 1500
tfrecords_mode: "ner"
max_steps: 80000
save_interval: 500
use_generalization: True

############ model ##############
num_hidden: 128
num_layers: 2
config_type: 0
config: 
  0: {encoder_type: "rnn", rnn_type: "bi", cell_type: "lstm"}
  1: {encoder_type: "bert", learning_rate: 0.00002, use_language_model: True,
      base_learning_rate: 0.000001}
  2: {encoder_type: "idcnn", learning_rate: 0.0005}
  3: {encoder_type: "transformer", learning_rate: 0.001, use_position: True}

  ######### daguan ###############
  4: {path_root: "data/ner/daguan/", ori_path: "train.txt", 
      test_path: "test.txt", 
      encoder_type: "elmo", rnn_type: "bi", cell_type: "lstm", use_attention: False,
      use_clr: False, clr_mode: 'triangular2', max_learning_rate: 0.0001, step_size: 500,
      learning_rate: 0.001, embedding_size: 128, embedding_type: 'word_embedding', 
      word_embedding_path: "corpus.txt.vec", rand_embedding: False, embedding_trainable: True,
      use_language_model: True, base_learning_rate: 0.001, use_generalization: False}

prepare_data: "false"
mode: "train"  #train\test\test_one

