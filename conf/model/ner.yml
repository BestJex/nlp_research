########## path ##########################
path_root: "data/ner/"
ori_path: "train_data"
# ori_path: "intent_ner.csv"


classes_path: "{encoder_type}/classes"
dict_path: "{encoder_type}/dict.pkl"
checkpoint_path: "{encoder_type}/checkpoint"
model_path: "{encoder_type}/model.pb"
label_path: "{encoder_type}/label"
tfrecords_path: "{encoder_type}/tfrecords"
export_dir_path: "{encoder_type}/model"
########### embedding ###########
embedding_size: 128
embedding_type: 'char_embedding'
rand_embedding: True
use_language_model: False

############# optim #############
learning_rate: 0.001
optimizer_type: "Adam"
#keep_prob: 0.5
clip_grad: 5
use_crf: True

############# clr #####################
use_clr: False
clr_mode: 'triangular'
max_learning_rate: 0.00001
step_size: 500

############ data ###############
maxlen: 256
batch_size: 128
dev_size: 1500
tfrecords_mode: "ner"
max_steps: 5000
save_interval: 300
use_generalization: True

############ model ##############
num_hidden: 128
num_layers: 3
config_type: 0
config: 
  0: {encoder_type: "rnn", rnn_type: "bi_lstm"}
  1: {encoder_type: "bert", learning_rate: 0.00002, use_language_model: True,
      base_learning_rate: 0.000001}
  2: {encoder_type: "idcnn", learning_rate: 0.0005}
  3: {encoder_type: "transformer", learning_rate: 0.001, use_position: True}

  ######### daguan ###############
  4: {path_root: "data/ner/daguan/", ori_path: "train.txt", 
      test_path: "test.txt", encoder_type: "rnn", rnn_type: "bi_lstm", 
      learning_rate: 0.05, embedding_size: 128, embedding_type: 'word_embedding', 
      word_embedding_path: "corpus.txt.vec", rand_embedding: False, 
      use_language_model: False, use_generalization: False}

prepare_data: "false"
mode: "train"  #train\test\test_one

